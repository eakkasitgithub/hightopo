{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eakkasitgithub/hightopo/blob/master/frame_capture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install required external modules**\n",
        "* opencv-python-headless 4.5.5.52 caused a [registermattype-from-cv2-cv2] error on Google Colab --> downgraded to the latest workable version 4.1.2.30"
      ],
      "metadata": {
        "id": "VU9L0AWOuBaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr\n",
        "!pip uninstall -y opencv-python-headless\n",
        "!pip install opencv-python-headless==4.1.2.30"
      ],
      "metadata": {
        "id": "B31OOU_-XhNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Functions Cell"
      ],
      "metadata": {
        "id": "2kxLiO6Q9IsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab Default Modules\n",
        "import time, sys, cv2, threading\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import queue as Queue\n",
        "import json\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "# External Module\n",
        "import easyocr\n",
        "\n",
        "# Buffers-less VideoCapture\n",
        "class VideoCapture:\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.cap = cv2.VideoCapture(name)\n",
        "        self.cap.set(cv2.CAP_PROP_FPS, 30)\n",
        "        self.q = Queue.Queue()\n",
        "        t = threading.Thread(target=self._reader)\n",
        "        t.daemon = True\n",
        "        t.start()\n",
        "\n",
        "    # read frames as soon as they are available, keeping only most recent one\n",
        "    def _reader(self):\n",
        "        while True:\n",
        "            ret, frame = self.cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            if not self.q.empty():\n",
        "                try:\n",
        "                    self.q.get_nowait()  # discard previous (unprocessed) frame\n",
        "                except Queue.Empty:\n",
        "                    pass\n",
        "            self.q.put(frame)\n",
        "\n",
        "    def read(self):\n",
        "        return self.q.get()\n",
        "\n",
        "\n",
        "# Initiate Jaided AI/Easy OCR\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "def easyocr_engine_reader(img, canvas, cy0, cx0):\n",
        "    # Jaided AI/Easy OCR\n",
        "    # Reader.readtext() includes img pre-processing pipeline to optimize img for the OCR engine, tests were done -- OpenCV img preprocessing not beneficially improve results compared to increase processing time\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    result = reader.readtext(img, allowlist='0123456789')\n",
        "\n",
        "    # Assign extracted result to returning list\n",
        "    extracted_numeric = 'nan'\n",
        "    for word in result:\n",
        "        extracted_numeric = word[1]\n",
        "\n",
        "    '''\n",
        "    --- Visualize result on canvas EasyOCR result structure\n",
        "    = [ [ [[x1, y1], [x2,y1], [x1, y2], [x2, y2]], text, confident level ], [ [...], text, cl], [ ......] ]\n",
        "    where x1, y1, x2, y2 are the bounding coordinate of the text\n",
        "          cy0, cx0 are the coordinate of cropped img relative to the full img\n",
        "    for word in result:\n",
        "        x1, y1, x2, y2 = int(word[0][0][0]), int(word[0][0][1]), int(word[0][2][0]), int(word[0][2][1])\n",
        "        cv2.rectangle(canvas, (cx0 + x1, cy0 + y1), (cx0 + x2, cy0 + y2), (255, 255, 0), 1)\n",
        "        cv2.putText(canvas, word[1], (cx0 + x1, cy0 + y1 + 12), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 0), 1)\n",
        "    '''\n",
        "    return extracted_numeric, canvas\n",
        "\n",
        "\n",
        "def CheckSignal(img):\n",
        "  valid = False\n",
        "  accum, count = '', 0\n",
        "  \n",
        "  resY, resX = img.shape[:2]\n",
        "  scaleY, scaleX = np.divide([resY, resX], [720, 1280])\n",
        "  scale = scaleY**2/scaleX\n",
        "\n",
        "  if scaleY == scaleX:\n",
        "    if np.all(img == 0):\n",
        "      accum = 'Blank frame detected.'\n",
        "    else:\n",
        "      y0, y1, x0, x1 = [int(i*scale) for i in [55, 83, 125, 300]]\n",
        "      signalframe = img[y0:y1, x0:x1, :]\n",
        "      signalframe = cv2.cvtColor(signalframe, cv2.COLOR_BGR2GRAY)\n",
        "      result = reader.readtext(signalframe, allowlist='')\n",
        "      for word in result:\n",
        "        accum += word[1] + ' '\n",
        "        for char in word[1]:\n",
        "          count += int(char.lower() in 'nosignal')\n",
        "\n",
        "      if (accum.lower() == 'nosignal') or (count > 7):\n",
        "        accum = accum + 'was read from the monitor.'\n",
        "      else:\n",
        "        valid = True\n",
        "  else:\n",
        "    accum = 'Distorted frame ratio.'\n",
        "\n",
        "  if valid == False:\n",
        "    print('Check signal: ', accum, 'input resolution: ', img.shape[:2], ' vid_ratio: ', img.shape[1]/img.shape[0], 'valid_scale:', scale)\n",
        "  return scale, valid\n",
        "\n",
        "\n",
        "def ExtractGraphLine(img, key):\n",
        "    h, w = img.shape[:2]\n",
        "    mask = np.zeros((h, w), np.uint8)\n",
        "\n",
        "    # Transform to gray colorspace\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Conditional image processing for each type of graph\n",
        "    if key in ['ECG']:\n",
        "        kernel = np.ones((2, 2), np.uint8)\n",
        "        gray = cv2.erode(gray, kernel, iterations=1)\n",
        "        gray = cv2.dilate(gray, (1,1), iterations=1)\n",
        "    if key in ['ART']:\n",
        "        gray[gray < (np.max(gray) * 0.45)] = 0\n",
        "\n",
        "    # threshold the image\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform opening on the thresholded image (erosion followed by dilation)\n",
        "    kernel = np.ones((2, 2), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Search for contours and select the biggest one and draw it on mask\n",
        "    contours, hierarchy = cv2.findContours(opening, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
        "    cnt = max(contours, key=cv2.contourArea)\n",
        "    cv2.drawContours(mask, [cnt], 0, 255, -1)\n",
        "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
        "\n",
        "    # Perform a bitwise operation\n",
        "    res = cv2.bitwise_not(mask)\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def TemporalSection(value):\n",
        "    TMavg = 3\n",
        "    SectionIndexArray = []\n",
        "    samples = value.shape[0]\n",
        "\n",
        "    # Peak Detection of Moving Variance Method\n",
        "    MovingVariance = np.zeros((samples - TMavg))\n",
        "    for index in range(samples - TMavg):\n",
        "        MovingVariance[index] = np.abs(np.var(value[index:index + TMavg]))\n",
        "    peaks, _ = find_peaks(MovingVariance, prominence=1)\n",
        "\n",
        "    if len(peaks):\n",
        "        if peaks[0] != 0:\n",
        "            peaks = np.insert(peaks, 0, 0)\n",
        "        if peaks[-1] != (samples - 1):\n",
        "            peaks = np.append(peaks, samples - 1)\n",
        "        SectionIndexArray = [[peaks[i], peaks[i + 1]] for i in range(len(peaks)-1)]\n",
        "\n",
        "    return SectionIndexArray\n",
        "\n",
        "\n",
        "def ReadGraph(img, x0, y0, key, zero_level, scale_h, scale_value, mask):\n",
        "    B, G, R = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
        "\n",
        "    for each in mask:\n",
        "        if each:\n",
        "            xroi0, xroi1, yroi0, yroi1 = each\n",
        "            xrel0 = max(0, xroi0 - x0)\n",
        "            xrel1 = max(0, xroi1 - x0)\n",
        "            yrel0 = max(0, yroi0 - y0)\n",
        "            yrel1 = max(0, yroi1 - y0)\n",
        "            ROI = img[yrel0:yrel1, xrel0:xrel1, :]\n",
        "            mask_gray = cv2.cvtColor(ROI, cv2.COLOR_BGR2GRAY)\n",
        "            _, bin_mask = cv2.threshold(mask_gray, 10, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "            mask = cv2.bitwise_not(bin_mask)\n",
        "            masked_ROI = cv2.bitwise_or(ROI, ROI, mask=mask)\n",
        "            # cv2.imshow(key + 'img_masked', mask)\n",
        "            img[yrel0:yrel1, xrel0:xrel1, :] = masked_ROI\n",
        "\n",
        "    # Conditional image processing for each type of graph\n",
        "    if key in ['ECG', 'Pleth']:\n",
        "        # Remove white notation from image\n",
        "        mask_white = (B >= G) & (R >= G)\n",
        "        img[np.where(mask_white == 1)] = [0, 0, 0]\n",
        "\n",
        "    if key in ['ART']:\n",
        "        mask_level = (R > 120)\n",
        "        img[np.where(mask_level == 0)] = [0, 0, 0]\n",
        "\n",
        "    crop_img_gray = ExtractGraphLine(img,key)\n",
        "    index = np.array([np.nanargmax(crop_img_gray[:, col]) for col in range(np.shape(crop_img_gray)[1])])\n",
        "\n",
        "    # Scaling Abstract Value to Related Dimensional Units\n",
        "    frame_h, frame_w = img.shape[:2]\n",
        "    value = frame_h - index\n",
        "    value = ((value - zero_level) * scale_value) / scale_h\n",
        "    extracted_value = value\n",
        "\n",
        "    # Visualize graphical recreation of extracted value\n",
        "    canvas = np.zeros((img.shape[0], img.shape[1]), np.uint8)\n",
        "    for col in range(frame_w):\n",
        "        i = index[col]\n",
        "        if i != 0:\n",
        "            try:\n",
        "                if not (previous_range in range(i - 1, i + 1)):\n",
        "                    if previous_range < i:\n",
        "                        canvas[previous_range:i, col] = 255\n",
        "                    else:\n",
        "                        canvas[i:previous_range, col] = 255\n",
        "                else:\n",
        "                    canvas[i, col] = 255\n",
        "            except:\n",
        "                # print(i, 'invalid i value')\n",
        "                pass\n",
        "            previous_range = i\n",
        "\n",
        "    interval = TemporalSection(extracted_value)\n",
        "    extracted_value = [extracted_value[interval[i][0]: interval[i][1]].tolist() for i in range(len(interval))]\n",
        "\n",
        "    return extracted_value, canvas\n",
        "\n",
        "# Define storing parameters and biosignals of interest \n",
        "extracted_biosignals, f_crop = {}, {}\n",
        "biosignals = {'HR': {'fLoc': [78, 77 + 94, 56, 56 + 237], 'dtype': 'num'}, \n",
        " 'RR': {'fLoc': [599, 599 + 63, 200, 200 + 94], 'dtype': 'num'}, \n",
        " 'N_SBP': {'fLoc': [223, 223 + 48, 57, 57 + 109], 'dtype': 'num'}, \n",
        " 'N_DBP': {'fLoc': [222, 222 + 47, 174, 174 + 112], 'dtype': 'num'}, \n",
        " 'N_MAP': {'fLoc': [269, 269 + 36, 133, 133 + 73], 'dtype': 'num'},\n",
        " 'A_SBP': {'fLoc': [343, 343 + 48, 63, 63 + 109], 'dtype': 'num'}, \n",
        " 'A_DBP': {'fLoc': [344, 344 + 46, 179, 179 + 112], 'dtype': 'num'}, \n",
        " 'A_MAP': {'fLoc': [389, 389 + 36, 143, 143 + 73], 'dtype': 'num'}, \n",
        " 'SpO2': {'fLoc': [492, 492 + 79, 162, 162 + 132], 'dtype': 'num'},\n",
        " 'ECG': {'fLoc': [64, 240, 503, 1280], 'dtype': 'gr', 'label': [[176, 39], 1, 'mV'], 'mask': [[]]}, \n",
        " 'ART': {'fLoc': [322, 433, 503, 1280], 'dtype': 'gr', 'label': [[432, 111], 200, 'mmHg'], 'mask': [[1180, 1180 + 29, 322, 322 + 16], [1241, 1241 + 24, 322, 322 + 12], [1242, 1242 + 8, 424, 424 + 9]]}, \n",
        " 'Pleth': {'fLoc': [470, 584, 503, 1280], 'dtype': 'gr', 'label': [[584, 584 - 476], 1, ''], 'mask': [[1252, 1252 + 17, 472, 472 + 15], [1245, 1245 + 31, 492, 492 + 14]]}, \n",
        " 'Resp': {'fLoc': [584, 713, 503, 1280], 'dtype': 'gr', 'label': [[713, 713 - 584], 1, '%'], 'mask': [[1252, 1252 + 16, 585, 585 + 14]]}}\n",
        "# -- For web streaming capture -- Working only these four channels at the moment\n",
        "#VIDEO_URL = \"rtmp://110.238.114.246:1935/live/icu-00\"\n",
        "VIDEO_URL = \"rtmp://110.238.114.246:1935/live/icu-04\"\n",
        "#VIDEO_URL = \"rtmp://110.238.114.246:1935/live/icu-06\"\n",
        "#VIDEO_URL = \"rtmp://110.238.114.246:1935/live/icu-12\"\n",
        "\n",
        "stream_capture = VideoCapture(VIDEO_URL)\n",
        "\n",
        "if (stream_capture.cap.isOpened() == False):\n",
        "    print('!!! Unable to open URL')\n",
        "    sys.exit(-1)\n",
        "\n",
        "while(True):\n",
        "    # -- Read one frame\n",
        "    frame = stream_capture.read()\n",
        "    #path = '/content/drive/MyDrive/Work/med_cmu_project/icu_surg/streaming/signal1.png'\n",
        "    #frame = cv2.imread(path)\n",
        "    t_cap = str(time.ctime())\n",
        "    \n",
        "    # -- Use the frame object to extract numbers and time series data from here\n",
        "\n",
        "    # Visualize Captured Frame\n",
        "    '''\n",
        "    clear_output()  \n",
        "    cv2_imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) \n",
        "    '''\n",
        "\n",
        "    # Check signal validity by calling function 'CheckSignal'\n",
        "    scale, valid = CheckSignal(frame)\n",
        "    if valid:\n",
        "\n",
        "      # Extract numeric and graphical value into DataFrame (df_output)\n",
        "      for key in biosignals.keys():\n",
        "        y0, y1, x0, x1 = biosignals[key]['fLoc'][0], biosignals[key]['fLoc'][1], biosignals[key]['fLoc'][2], biosignals[key]['fLoc'][3]\n",
        "        y0, y1, x0, x1 = [ int(i*scale) for i in [y0, y1] + [x0, x1]]\n",
        "        f_crop[key] = frame[y0: y1, x0: x1, :]\n",
        "        cv2_imshow(cv2.cvtColor(f_crop[key], cv2.COLOR_BGR2RGB)) \n",
        "        datatype = biosignals[key]['dtype']\n",
        "        if datatype == 'gr':\n",
        "          label = biosignals[key]['label']\n",
        "          rel0 = y1 - int(scale*label[0][0])\n",
        "          scale_h, scale_value = int(scale*label[0][1]), label[1]\n",
        "          # OGR by calling series of nested functions 'ReadGraph'\n",
        "          extracted_biosignals[key], graphic_canvas = ReadGraph(f_crop[key], x0, y0, key, rel0, scale_h, scale_value, biosignals[key]['mask'])\n",
        "\n",
        "        elif datatype == 'num':\n",
        "          # OCR by calling the function 'easyocr_enginer_reader'\n",
        "          extracted_biosignals[key], ocr_canvas = easyocr_engine_reader(f_crop[key], frame, y0, x0)\n",
        "        \n",
        "        else:\n",
        "          extracted_biosignals[key] = 'data type is not determined.'\n",
        "        \n",
        "      # Covert Dict --> JSON for the Firebase storage  \n",
        "      extracted_biosignals['timestamp'] = t_cap\n",
        "      json_output = json.dumps(extracted_biosignals)\n",
        "      print(json_output)\n",
        "      \n",
        "      # Save frame.jpg with RGB profile\n",
        "      cv2.imwrite(t_cap + \".jpg\", cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    else:\n",
        "      print('The frame was not processed, no JSON output created on', t_cap)\n",
        "      \n",
        "    # Processing interval (s)\n",
        "    time.sleep(5)\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "c7pCT5IPQlxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab Default Modules\n",
        "import time, sys, cv2, threading\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import queue as Queue\n",
        "import json\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "from scipy.signal import find_peaks\n",
        "from operator import itemgetter\n",
        "import math\n",
        "\n",
        "# External Module\n",
        "import easyocr\n",
        "\n",
        "class VideoCapture:\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.cap = cv2.VideoCapture(name)\n",
        "        self.cap.set(cv2.CAP_PROP_FPS, 30)\n",
        "        self.q = Queue.Queue()\n",
        "        t = threading.Thread(target=self._reader)\n",
        "        t.daemon = True\n",
        "        t.start()\n",
        "\n",
        "    # read frames as soon as they are available, keeping only most recent one\n",
        "    def _reader(self):\n",
        "        while True:\n",
        "            ret, frame = self.cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            if not self.q.empty():\n",
        "                try:\n",
        "                    self.q.get_nowait()  # discard previous (unprocessed) frame\n",
        "                except Queue.Empty:\n",
        "                    pass\n",
        "            self.q.put(frame)\n",
        "\n",
        "    def read(self):\n",
        "        return self.q.get()\n",
        "\n",
        "def findPosition(frame,template):\n",
        "  path = '/content/drive/MyDrive/Work/med_cmu_project/icu_surg/streaming/'+template+'.png'\n",
        "  img1 = cv2.imread(path)\n",
        "  gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  res = cv2.matchTemplate(frame,gray,cv2.TM_CCOEFF_NORMED)\n",
        "  min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
        "\n",
        "  #w, h = gray.shape[::-1]\n",
        "  #top_left = max_loc\n",
        "  #bottom_right = (top_left[0] + w, top_left[1] + h)\n",
        "  return max_loc,max_val\n",
        "\n",
        "def ocr_reader(img):\n",
        "  # Jaided AI/Easy OCR\n",
        "  # Reader.readtext() includes img pre-processing pipeline to optimize img for the OCR engine, tests were done -- OpenCV img preprocessing not beneficially improve results compared to increase processing time\n",
        "  #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  return reader.readtext(img, allowlist='0123456789/()-?')\n",
        "\n",
        "# Initiate Jaided AI/Easy OCR\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# -- For web streaming capture -- Working only these four channels at the moment\n",
        "VIDEO_URL = \"rtmp://110.238.114.246:1935/live/icu-00\"\n",
        "#VIDEO_URL = \"rtmp://110.238.114.246:1935/live/icu-04\"\n",
        "#VIDEO_URL = \"rtmp://110.238.114.246:1935/live/icu-06\"\n",
        "#VIDEO_URL = \"rtmp://110.238.114.246:1935/live/icu-12\"\n",
        "\n",
        "stream_capture = VideoCapture(VIDEO_URL)\n",
        "\n",
        "if (stream_capture.cap.isOpened() == False):\n",
        "    print('!!! Unable to open URL')\n",
        "    sys.exit(-1)\n",
        "\n",
        "templates = ['hr','spo2','art','pap','cvp','rr']\n",
        "left = 1380\n",
        "while(True):\n",
        "    # -- Read one frame\n",
        "    frame = stream_capture.read()\n",
        "    #cv2_imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "    #path = '/content/drive/MyDrive/Work/med_cmu_project/icu_surg/streaming/signal1.png'\n",
        "    #frame = cv2.imread(path)\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    gap = 10\n",
        "    for i in templates:\n",
        "      top_left,prop = findPosition(gray,i)\n",
        "      #cv2.rectangle(frame,(left,top_left[1]), (left+300,top_left[1]+120), 255, 2)\n",
        "      img = gray[top_left[1]:top_left[1]+120,left:left+300]\n",
        "      thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
        "      hh, ww = thresh.shape\n",
        "      white = np.where(thresh==255)\n",
        "      xmin, ymin, xmax, ymax = np.min(white[1]), np.min(white[0]), np.max(white[1]), np.max(white[0])\n",
        "\n",
        "      cv2.rectangle(frame,(left+xmin-gap,top_left[1]+ymin-gap), (left+xmax+gap,top_left[1]+ymax+gap), 255, 2)\n",
        "      print(i)\n",
        "      if prop > 0.9:\n",
        "        result = ocr_reader(gray[top_left[1]+ymin-gap:top_left[1]+ymax+gap,left+xmin-gap:left+xmax+gap])\n",
        "        #Get the best result\n",
        "        result = max(result,key=itemgetter(2))\n",
        "        print(result)\n",
        "      else:\n",
        "        print('No matched signal')\n",
        "    cv2_imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) \n",
        "    break\n",
        "\n",
        "stream_capture.cap.release()"
      ],
      "metadata": {
        "id": "fjxILBbOIvlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read data from firebase database"
      ],
      "metadata": {
        "id": "L6XmbijGQUIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install firebase_admin"
      ],
      "metadata": {
        "id": "8HF3WnvDQRSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import firebase_admin\n",
        "from firebase_admin import db\n",
        "from firebase_admin import firestore\n",
        "from datetime import datetime\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import lzma\n",
        "import numpy as np\n",
        "\n",
        "import zlib\n",
        "\n",
        "path = '/content/drive/MyDrive/Work/med_cmu_project/icu_surg/icusignal-firebase-adminsdk-um0pn-83649d5ef3.json'\n",
        "\n",
        "if not firebase_admin._apps:\n",
        "\tcred_obj = firebase_admin.credentials.Certificate(path)\n",
        "\tdefault_app = firebase_admin.initialize_app(cred_obj)\n",
        "\n",
        "db = firestore.client()\n",
        "'''\n",
        "doc_ref = db.collection('icusurg-data').document('bed-01')\n",
        "t = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "doc_ref.set({\n",
        "    'o2':{t: 98}\n",
        "}, merge=True)\n",
        "\n",
        "emp_ref = db.collection('icusurg-data')\n",
        "docs = emp_ref.stream()\n",
        "\n",
        "for doc in docs:\n",
        "    print('{} => {} '.format(doc.id, doc.to_dict()))\n",
        "'''\n",
        "\n",
        "doc_ref = db.collection('icusurg-frame').document('bed-01')\n",
        "\n",
        "path = '/content/drive/MyDrive/Work/med_cmu_project/icu_surg/streaming/signal1.png'\n",
        "frame = cv2.imread(path)\n",
        "print(frame.shape)\n",
        "#compressor = lzma.LZMACompressor(format=lzma.FORMAT_RAW, filters=[{\"id\": lzma.FILTER_LZMA2}])\n",
        "#s = lzma.compress(frame)\n",
        "s = zlib.compress(frame, zlib.Z_BEST_COMPRESSION)\n",
        "print(frame.flatten()[6000000:6000100])\n",
        "print(len(s))\n",
        "\n",
        "#t = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "#doc_ref.set({'timestamp':t, 'shape':list(frame.shape), 'image':s}, merge=False)\n",
        "\n",
        "'''\n",
        "docs = db.collection('icusurg-frame').stream()\n",
        "for doc in docs:\n",
        "  d = doc.to_dict()\n",
        "  print(d['image'])\n",
        "  data = lzma.decompress(d['image'])\n",
        "  data = np.frombuffer(data, dtype=np.uint8)\n",
        "  data = data.reshape((*d['shape'], ))\n",
        "  cv2_imshow(cv2.cvtColor(data, cv2.COLOR_BGR2RGB)) \n",
        "'''\n",
        "'''\n",
        "path = '/content/drive/MyDrive/Work/med_cmu_project/icu_surg/streaming/signal1.png'\n",
        "frame = cv2.imread(path)\n",
        "print(frame.shape)\n",
        "s = lzma.compress(frame)\n",
        "print(s)\n",
        "'''"
      ],
      "metadata": {
        "id": "Lexkl-CYQaU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete collection\n",
        "import firebase_admin\n",
        "from firebase_admin import db\n",
        "from firebase_admin import firestore\n",
        "\n",
        "path = '/content/drive/MyDrive/Work/med_cmu_project/icu_surg/icusignal-firebase-adminsdk-um0pn-83649d5ef3.json'\n",
        "\n",
        "if not firebase_admin._apps:\n",
        "\tcred_obj = firebase_admin.credentials.Certificate(path)\n",
        "\tdefault_app = firebase_admin.initialize_app(cred_obj)\n",
        "\n",
        "db = firestore.client()\n",
        "\n",
        "def delete_collection(coll_ref, batch_size):\n",
        "    docs = coll_ref.limit(batch_size).stream()\n",
        "    deleted = 0\n",
        "\n",
        "    for doc in docs:\n",
        "        print(f'Deleting doc {doc.id} => {doc.to_dict()}')\n",
        "        doc.reference.delete()\n",
        "        deleted = deleted + 1\n",
        "\n",
        "    if deleted >= batch_size:\n",
        "        return delete_collection(coll_ref, batch_size)\n",
        "\n",
        "#delete_collection(db.collection('icusurg-data'), 100)\n",
        "\n",
        "emp_ref = db.collection('icusurg-data')\n",
        "docs = emp_ref.stream()\n",
        "n = 1\n",
        "for doc in docs:\n",
        "  n = n+1\n",
        "print(n)"
      ],
      "metadata": {
        "id": "WJSH0aVXSgAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yqW082EdvcDt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}